import torch
import os
import re
from peft import PeftModel
from transformers import AutoModelForCausalLM, AutoTokenizer

BASE_MODEL_PATH = "Qwen2.5-0.5B-Instruct"
LORA_MODEL_PATH = "health_advice_qwen0.5b_cpu_final"
DEVICE = "cpu"

def load_model_and_tokenizer():
    print("ğŸ“Œ æ­£åœ¨åŠ è½½æ¨¡å‹ï¼Œè¯·ç¨å€™...")
    tokenizer = AutoTokenizer.from_pretrained(
        BASE_MODEL_PATH,
        trust_remote_code=True,
        padding_side="right"
    )
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
    base_model = AutoModelForCausalLM.from_pretrained(
        BASE_MODEL_PATH,
        trust_remote_code=True,
        dtype=torch.float32,
        device_map=DEVICE,
        low_cpu_mem_usage=True,
        local_files_only=True
    )
    base_model.eval()
    finetuned_model = PeftModel.from_pretrained(
        base_model,
        LORA_MODEL_PATH,
        local_files_only=True
    )

    print("âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼")
    return finetuned_model, tokenizer

def generate_health_advice(model, tokenizer, habit, max_new_tokens=300):
    prompt = f"""ç”¨æˆ·æœ‰ä¸è‰¯ç”Ÿæ´»ä¹ æƒ¯ï¼š{habit}ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚ç”Ÿæˆå…»ç”Ÿå»ºè®®ï¼š
1. ä»…ç”Ÿæˆ3æ¡å»ºè®®ï¼Œä»1åˆ°3ç¼–å·ï¼Œæ ¼å¼ä¸ºâ€œæ•°å­—ã€å»ºè®®å†…å®¹ã€‚â€ï¼›
2. æ¯æ¡å»ºè®®ç®€æ´å®ç”¨ï¼Œ10-20å­—ï¼Œä»¥å¥å·ç»“å°¾ï¼Œæ— å¤šä½™è§£é‡Šï¼›
3. å†…å®¹ç´§æ‰£{habit}ï¼Œä¸é‡å¤ã€ä¸æˆªæ–­ï¼Œæ— ä»»ä½•å¯’æš„æˆ–é¢å¤–è¯´æ˜ã€‚"""
    
    inputs = tokenizer(
        prompt,
        return_tensors="pt",
        truncation=True,
        max_length=512  
    ).to(DEVICE)
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=max_new_tokens,
            temperature=0.6,
            top_p=0.85,
            repetition_penalty=1.5,
            do_sample=True,
            eos_token_id=tokenizer.eos_token_id,
            pad_token_id=tokenizer.pad_token_id,
            num_beams=4,
            use_cache=True,
            early_stopping=True,
            max_time=40.0
        )
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    advice = response.split(prompt)[-1].strip()
    advice_sentences = re.findall(r'[123][ã€.ï¼š: ]*(.*?ã€‚)', advice)
    valid_sentences = []
    for sent in advice_sentences:
        sent = sent.strip()
        if sent and len(sent) >= 8 and sent not in valid_sentences:
            valid_sentences.append(sent)
    # ğŸ”¥ ä¿ç•™é€šç”¨å…œåº•å»ºè®®ï¼ˆå·²ç§»é™¤ç†¬å¤œä¸“å±éƒ¨åˆ†ï¼‰
    default_advice = [
        "è§„å¾‹ä½œæ¯ï¼Œæ¯å¤©ä¿è¯8å°æ—¶ç¡çœ ã€‚",
        "é¥®é£Ÿå‡è¡¡ï¼Œå¤šåƒæ–°é²œè”¬èœæ°´æœã€‚",
        "æ¯å¤©é€‚åº¦è¿åŠ¨ï¼Œå¢å¼ºèº«ä½“æŠµæŠ—åŠ›ã€‚"
        ]
    final_sentences = valid_sentences[:3]
    need_add = 3 - len(final_sentences)
    if need_add > 0:
        for adv in default_advice:
            if adv not in final_sentences and need_add > 0:
                final_sentences.append(adv)
                need_add -= 1
    final_advice = []
    for i, sent in enumerate(final_sentences[:3], 1):
        final_advice.append(f"{i}ã€{sent}")

    return "\n".join(final_advice)

def main():
    model, tokenizer = load_model_and_tokenizer()
    print("\n" + "="*80)
    print("ğŸ¯ å…»ç”Ÿå»ºè®®åŠ©æ‰‹ - åŸºäºQwen2.5-0.5B LoRAå¾®è°ƒæ¨¡å‹")
    print("ğŸ’¡ è¾“å…¥ä½ çš„ä¸è‰¯ç”Ÿæ´»ä¹ æƒ¯ï¼Œæˆ‘ä¼šä¸ºä½ ç”Ÿæˆ3æ¡å®šåˆ¶åŒ–å…»ç”Ÿå»ºè®®ï¼ˆè¾“å…¥'é€€å‡º'/'q'ç»“æŸç¨‹åºï¼‰")
    print("="*80 + "\n")
    while True:
        user_input = input("è¯·è¾“å…¥ä½ çš„ä¸è‰¯ç”Ÿæ´»ä¹ æƒ¯ï¼š").strip()
        if user_input.lower() in ["é€€å‡º", "q", "quit", "exit"]:
            print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼Œç¥ä½ èº«ä½“å¥åº·ï¼")
            break
        if not user_input:
            print("ğŸ¤–è¯·è·Ÿæˆ‘è¯´ä¸‹ä½ çš„å°é—®é¢˜å§\n")
            continue
        print("\nğŸ¤– æ­£åœ¨ä¸ºä½ ç”Ÿæˆå…»ç”Ÿå»ºè®®...\n")
        try:
            advice = generate_health_advice(model, tokenizer, user_input)
            print("âœ… å…»ç”Ÿå»ºè®®ï¼š")
            print("-"*60)
            print(advice)
            print("-"*60 + "\n")
        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¤±è´¥ï¼š{str(e)}\n")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç¨‹åºå·²ç»ˆæ­¢ï¼Œæ„Ÿè°¢ä½¿ç”¨ï¼")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¼‚å¸¸ï¼š{str(e)}")
        print("ğŸ’¡ è¯·æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œæˆ–é‡æ–°è¿è¡Œç¨‹åºã€‚")